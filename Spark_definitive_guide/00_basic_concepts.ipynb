{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "37b82fe3-17ac-4537-9479-ccec2c579879",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f306a3-74bf-4a52-9be7-5aa547409002",
   "metadata": {},
   "source": [
    "# Starting a basic SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dcda3f1-12ce-4a24-b95d-619080a98f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/01 19:23:55 WARN Utils: Your hostname, luan-Dell-G15-5520 resolves to a loopback address: 127.0.1.1; using 192.168.1.12 instead (on interface wlp0s20f3)\n",
      "23/11/01 19:23:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/01 19:24:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"basic_app\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e9eba5-06cb-4ae3-86a3-7be32efc616e",
   "metadata": {},
   "source": [
    "# First example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3917c1f5-00e2-4549-986b-8da21097c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "myRange = spark.range(1000).toDF(\"number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb5342bd-2cd8-41cf-8f77-babcccb4331b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "myRange.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd04de1-a388-4d56-9410-616560535166",
   "metadata": {},
   "source": [
    "## Decomposing myRange variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f47e9-328f-46a8-993e-430030ea9b30",
   "metadata": {},
   "source": [
    "### Docs: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebc8c1-06f6-4c7b-8bf2-8180a784b495",
   "metadata": {},
   "source": [
    "### Spark functions: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/functions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d9cabf4-a672-4c8e-bd3e-239fd2f75cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "+---+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The custom input is id\n",
    "spark.range(1000).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f28c05-c37a-4e21-be3e-7a8e1a5c7ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renaming id as number\n",
    "spark.range(1000).toDF(\"number\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce68045d-4c9e-43a5-a781-9e179acbb671",
   "metadata": {},
   "source": [
    "# Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa26d2cf-3d53-48cd-8acf-ef03b444803b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     2|\n",
      "|     4|\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number % 2 = 0 is a SQL query\n",
    "divisBy2 = myRange.where(\"number % 2 = 0\")\n",
    "divisBy2.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59ee107-c4dc-483e-8022-bed8682424c5",
   "metadata": {},
   "source": [
    "## Alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906ff172-9af6-476a-b37b-16b13526df25",
   "metadata": {},
   "source": [
    "### using F.col spark function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373f542b-c79a-4c64-bf47-4d5872beb3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     2|\n",
      "|     4|\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "divisBy2 = myRange.where(F.col('number') % 2 == 0)\n",
    "divisBy2.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5bf957-2ab2-4f97-9d41-081a95592e82",
   "metadata": {},
   "source": [
    "### using dataframe structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26d3245-743b-4bdc-9ba4-d226eacebdc7",
   "metadata": {},
   "source": [
    "#### As an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb1adce7-aea4-4c9b-96f0-6e38733f464e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     2|\n",
      "|     4|\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "divisBy2 = myRange.where(myRange.number % 2 == 0)\n",
    "divisBy2.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec027d7-ad21-4065-a2f7-3a4e17016f2f",
   "metadata": {},
   "source": [
    "#### When the column name has spaces, use the form below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1e8a1c9-ad0c-4a3e-b2de-b55bd3230ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     2|\n",
      "|     4|\n",
      "+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "divisBy2 = myRange.where(myRange['number'] % 2 == 0)\n",
    "divisBy2.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0adf9b-4886-4ddd-bfaa-a139293393f5",
   "metadata": {},
   "source": [
    "# Dataframe actions. Docs: https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/dataframe.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ca89c7-174d-4f2f-bd12-0388489babc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divisBy2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dd9a275-f96c-4395-9dea-7db2798c4b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- number: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "divisBy2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02c62b0f-9e11-4b4e-8c94-7de9dfc7fff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('number', 'bigint')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divisBy2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb32db7-e637-4ded-9790-0f7d1c693145",
   "metadata": {},
   "source": [
    "## quick tip: is useful to have dtypes as a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7d633be-f70a-475e-9241-e416a4cbc6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {key:value for key,value in divisBy2.dtypes}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3f795-6580-4bc7-aa45-5390d2724434",
   "metadata": {},
   "source": [
    "## To check the jobs, go to: http://localhost:4040/jobs/ . Ignore the clock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f92fea4-f0c5-45fc-b1d9-bb4801c6b361",
   "metadata": {},
   "source": [
    "# An end-to-end example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "142ea708-ab3a-42ae-8e6b-6cc467eec7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightData2015 = spark\\\n",
    ".read\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".csv(\"../../../spark_data_examples/flight-data/csv/2015-summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a31dbf-b457-490c-bb00-01d44210fa6d",
   "metadata": {},
   "source": [
    "## Checking the types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00be75be-2385-449e-9633-21ee8c4ab66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DEST_COUNTRY_NAME: string (nullable = true)\n",
      " |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dad2a9-5b14-4271-9739-c8dc29d0eaa1",
   "metadata": {},
   "source": [
    "## Getting a type dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c204019-476e-41a1-ba6f-afcfad55ed63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DEST_COUNTRY_NAME': 'string',\n",
       " 'ORIGIN_COUNTRY_NAME': 'string',\n",
       " 'count': 'int'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict = {key:value for key,value in flightData2015.dtypes}\n",
    "dtype_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee489936-ecc9-43f1-95db-23f8476095d4",
   "metadata": {},
   "source": [
    "## Use of take"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a41d0c9b-1d95-4ad6-851c-f92c6c3367c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Romania', count=15),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Croatia', count=1),\n",
       " Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Ireland', count=344)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData2015.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda06e1-c863-43c4-984a-e196312b45a7",
   "metadata": {},
   "source": [
    "## Sorting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2b622a2-0e91-427d-a10e-5576b2237628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: int]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData2015.sort(\"count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08892d7-4cac-458f-8c39-1ea529bd8511",
   "metadata": {},
   "source": [
    "## Explaining the operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8228e26d-0962-48f9-9056-1fb4a03878a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#70 ASC NULLS FIRST], true, 0\n",
      "   +- Exchange rangepartitioning(count#70 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=171]\n",
      "      +- FileScan csv [DEST_COUNTRY_NAME#68,ORIGIN_COUNTRY_NAME#69,count#70] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/spark_data_examples/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.sort(\"count\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33be53-416e-48d9-a22e-d8d7ee374f49",
   "metadata": {},
   "source": [
    "## Changing the number of partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70459291-fddc-4799-98d5-ab7a0f04d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c05da5d6-297b-414c-a02f-5fef259fb93f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='United States', ORIGIN_COUNTRY_NAME='Singapore', count=1),\n",
       " Row(DEST_COUNTRY_NAME='Moldova', ORIGIN_COUNTRY_NAME='United States', count=1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flightData2015.sort(\"count\").take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a3fcfe-38b5-42de-871b-81890a4e8515",
   "metadata": {},
   "source": [
    "## Explaining again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c54c7e5-97a6-4994-8899-3e90ca178d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#70 ASC NULLS FIRST], true, 0\n",
      "   +- Exchange rangepartitioning(count#70 ASC NULLS FIRST, 5), ENSURE_REQUIREMENTS, [plan_id=187]\n",
      "      +- FileScan csv [DEST_COUNTRY_NAME#68,ORIGIN_COUNTRY_NAME#69,count#70] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/spark_data_examples/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string,ORIGIN_COUNTRY_NAME:string,count:int>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flightData2015.sort(\"count\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee38b6f4-a7e9-4d08-babf-9944596788da",
   "metadata": {},
   "source": [
    "## Check  http://localhost:4040/jobs/ again and see what happened"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952f9809-62f4-454e-be41-e3e3eb0a25d1",
   "metadata": {},
   "source": [
    "## Turning a SparkDataFrame into a SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a88b4b91-2bb4-4dd3-81a1-7570bb3897ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "flightData2015.createOrReplaceTempView(\"flight_data_2015\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa940650-ca2e-427f-81f7-2dc87eaf9ede",
   "metadata": {},
   "source": [
    "### SQL queries on the wild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "985dd73b-2c0b-4a2a-8d30-a82b507e3f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------+\n",
      "|DEST_COUNTRY_NAME|total_flights|\n",
      "+-----------------+-------------+\n",
      "|    United States|       411352|\n",
      "|           Canada|         8399|\n",
      "|           Mexico|         7140|\n",
      "|   United Kingdom|         2025|\n",
      "|            Japan|         1548|\n",
      "+-----------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT DEST_COUNTRY_NAME,\n",
    "                    SUM(count) AS total_flights\n",
    "             FROM flight_data_2015\n",
    "             GROUP BY DEST_COUNTRY_NAME\n",
    "             ORDER BY total_flights DESC \n",
    "             LIMIT 5;\"\"\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb89dd1-98ec-47d3-8328-3875f449d228",
   "metadata": {},
   "source": [
    "### A simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c586e22-9802-476e-9c5c-69d6734e8bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlWay = spark.sql(\"\"\"\n",
    "SELECT DEST_COUNTRY_NAME, count(1) AS counter\n",
    "FROM flight_data_2015\n",
    "GROUP BY DEST_COUNTRY_NAME\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "453797e3-8c4f-47d9-a6b0-c5d1717f8606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|DEST_COUNTRY_NAME|counter|\n",
      "+-----------------+-------+\n",
      "|    United States|    125|\n",
      "|          Moldova|      1|\n",
      "|          Bolivia|      1|\n",
      "+-----------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlWay.orderBy('counter',ascending = False).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b922e071-72e3-4f3c-9387-081720cf713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrameWay = flightData2015\\\n",
    ".groupBy(\"DEST_COUNTRY_NAME\")\\\n",
    ".count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2773bfe8-b481-4f38-bc6f-44598663846d",
   "metadata": {},
   "source": [
    "## Checking the differences between queries and DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3f1e720-a07e-422c-857f-dc2d592f206d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[DEST_COUNTRY_NAME#68], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#68, 5), ENSURE_REQUIREMENTS, [plan_id=293]\n",
      "      +- HashAggregate(keys=[DEST_COUNTRY_NAME#68], functions=[partial_count(1)])\n",
      "         +- FileScan csv [DEST_COUNTRY_NAME#68] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/spark_data_examples/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlWay.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78e665f5-000f-4d2a-96cd-ea7e31f8fdf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[DEST_COUNTRY_NAME#68], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(DEST_COUNTRY_NAME#68, 5), ENSURE_REQUIREMENTS, [plan_id=306]\n",
      "      +- HashAggregate(keys=[DEST_COUNTRY_NAME#68], functions=[partial_count(1)])\n",
      "         +- FileScan csv [DEST_COUNTRY_NAME#68] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/spark_data_examples/flight-data/csv/2015-summary.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<DEST_COUNTRY_NAME:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataFrameWay.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578bd7b0-00f5-48fb-8c37-19490f99d9af",
   "metadata": {},
   "source": [
    "## Getting statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3cccc419-4c86-4117-9cc5-71d6f22170bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+-------------+------------------+-----------+-------------------------------------------------------+\n",
      "|max(count)|min(count)|mean(count)|median(count)|        std(count)|mode(count)|percentile_approx(count, array(0.25, 0.5, 0.75), 10000)|\n",
      "+----------+----------+-----------+-------------+------------------+-----------+-------------------------------------------------------+\n",
      "|    370002|         1|1770.765625|         63.5|23126.516918551915|          1|                                          [14, 63, 268]|\n",
      "+----------+----------+-----------+-------------+------------------+-----------+-------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"SELECT max(count),\n",
    "                    min(count),\n",
    "                    mean(count),\n",
    "                    median(count),\n",
    "                    std(count),\n",
    "                    mode(count),\n",
    "                    percentile_approx(count, array(0.25, 0.5, 0.75))\n",
    "             FROM flight_data_2015\"\"\")\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dac5e6-a850-4a85-8086-41bb75feb0b5",
   "metadata": {},
   "source": [
    "## Recipe: extracting the statistics of all fields "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "57115f85-bbb3-4a97-99ec-c4ae71c6930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(table = 'flight_data_2015'):\n",
    "    field_list = [field.simpleString().split(':')[0] \n",
    "                  for field in \n",
    "                  spark.sql(f\"\"\"SELECT * FROM {table} LIMIT 1\"\"\").schema]\n",
    "    df_list = []\n",
    "    for field in field_list:\n",
    "        df = spark.sql(f\"\"\"SELECT \n",
    "                        '{field}' AS field_name,\n",
    "                        approx_count_distinct({field}) AS count_distinct,\n",
    "                        max({field}) AS max,\n",
    "                        min({field}) AS min,\n",
    "                        mean({field}) AS mean,\n",
    "                        median({field}) AS median,\n",
    "                        std({field}) AS std,\n",
    "                        std/mean AS cv,\n",
    "                        kurtosis({field}) AS kurt,\n",
    "                        skewness({field}) AS skew,\n",
    "                        mode({field}) AS mode,\n",
    "                        percentile_approx({field}, array(0.25, 0.5, 0.75)) AS percentiles,\n",
    "                        sum(nvl2({field},0,1)) AS null_count\n",
    "                 FROM {table}\"\"\")\n",
    "        df_list.append(df)\n",
    "    df_final = reduce(lambda df1,df2: df1.union(df2), df_list)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "506548d7-552e-4c02-ba9d-8cb129c5385c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_name</th>\n",
       "      <th>count_distinct</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>cv</th>\n",
       "      <th>kurt</th>\n",
       "      <th>skew</th>\n",
       "      <th>mode</th>\n",
       "      <th>percentiles</th>\n",
       "      <th>null_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEST_COUNTRY_NAME</td>\n",
       "      <td>121</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORIGIN_COUNTRY_NAME</td>\n",
       "      <td>116</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>Angola</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>count</td>\n",
       "      <td>164</td>\n",
       "      <td>370002</td>\n",
       "      <td>1</td>\n",
       "      <td>1770.765625</td>\n",
       "      <td>63.5</td>\n",
       "      <td>23126.516919</td>\n",
       "      <td>13.06018</td>\n",
       "      <td>250.047098</td>\n",
       "      <td>15.861327</td>\n",
       "      <td>1</td>\n",
       "      <td>[14.0, 63.0, 268.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            field_name  count_distinct      max      min         mean  median  \\\n",
       "0    DEST_COUNTRY_NAME             121   Zambia  Algeria          NaN     NaN   \n",
       "1  ORIGIN_COUNTRY_NAME             116  Vietnam   Angola          NaN     NaN   \n",
       "2                count             164   370002        1  1770.765625    63.5   \n",
       "\n",
       "            std        cv        kurt       skew           mode  \\\n",
       "0           NaN       NaN         NaN        NaN  United States   \n",
       "1           NaN       NaN         NaN        NaN  United States   \n",
       "2  23126.516919  13.06018  250.047098  15.861327              1   \n",
       "\n",
       "           percentiles  null_count  \n",
       "0                 None           0  \n",
       "1                 None           0  \n",
       "2  [14.0, 63.0, 268.0]           0  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4d55ccc6-5f35-4820-a7a6-3a208b819237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|nvl2(count, 0, 1)|\n",
      "+-----------------+\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "|                0|\n",
      "+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"\"\"SELECT nvl2('count',0,1) FROM flight_data_2015\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c395c8-95b1-4bd7-bb14-b2da63b720d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
