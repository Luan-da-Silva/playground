{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8ecc5d-8fd0-46ec-89d3-638386c4c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_tools.setup import setup\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a44136-1ac4-4ce5-baaf-6b60ed29b964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce,partial\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "159d2d6c-d388-4e1b-bf96-abea42bbd973",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/30 14:02:50 WARN Utils: Your hostname, luan-Dell-G15-5520 resolves to a loopback address: 127.0.1.1; using 192.168.1.12 instead (on interface wlp0s20f3)\n",
      "23/10/30 14:02:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/10/30 14:02:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/30 14:02:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as \"spark\"\n"
     ]
    }
   ],
   "source": [
    "spark = setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b986db-ec88-4a43-91ca-2243e811971d",
   "metadata": {},
   "source": [
    "# Tip 1: Alias is your friends (AS is Good practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e17a5d33-0b8c-4116-98d6-220e010695f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"SELECT\n",
    "\tcustomer_id,\n",
    "\tfirst_name\n",
    "FROM\n",
    "\tcustomer\n",
    "\"\"\"\n",
    "query2 = \"\"\"SELECT customer_id,amount,payment_date FROM payment\"\"\"\n",
    "df1 = spark.sql(query1)\n",
    "df2 = spark.sql(query2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11789ea3-8469-44d0-9893-e84733794bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------+--------------------+\n",
      "|customer_id|first_name|amount|        payment_date|\n",
      "+-----------+----------+------+--------------------+\n",
      "|         28|   Cynthia|  2.99|2007-05-14 13:44:...|\n",
      "|        111|    Carmen|  2.99|2007-05-14 13:44:...|\n",
      "|        497|   Gilbert|  4.99|2007-05-14 13:44:...|\n",
      "|        496|     Tyler|  2.99|2007-05-14 13:44:...|\n",
      "|        596|   Enrique|  0.99|2007-05-14 13:44:...|\n",
      "|        516|     Elmer|  0.00|2007-05-14 13:44:...|\n",
      "|        300|      John|  4.99|2007-05-14 13:44:...|\n",
      "|         53|   Heather|  7.98|2007-05-14 13:44:...|\n",
      "|        412|     Allen|  0.99|2007-05-14 13:44:...|\n",
      "|        296|    Ramona|  2.99|2007-05-14 13:44:...|\n",
      "|        587|    Sergio|  0.99|2007-05-14 13:44:...|\n",
      "|        115|     Wendy|  2.99|2007-05-14 13:44:...|\n",
      "|         44|     Marie|  4.99|2007-05-14 13:44:...|\n",
      "|        597|   Freddie|  4.99|2007-05-14 13:44:...|\n",
      "|        192|    Laurie|  4.99|2007-05-14 13:44:...|\n",
      "|        155|      Gail|  7.98|2007-05-14 13:44:...|\n",
      "|        236|    Marcia|  0.99|2007-05-14 13:44:...|\n",
      "|        530|    Darryl|  2.99|2007-05-14 13:44:...|\n",
      "|        336|    Joshua|  0.99|2007-05-14 13:44:...|\n",
      "|        211|    Stacey|  4.99|2007-05-14 13:44:...|\n",
      "+-----------+----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(df2,on = ['customer_id'], how = 'inner')\\\n",
    "   .orderBy('payment_date',ascending = False)\\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07416f8c-1ab2-447a-9ed9-1ac3d919bfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------+--------------------+\n",
      "|customer_id|first_name|amount|        payment_date|\n",
      "+-----------+----------+------+--------------------+\n",
      "|         41| Stephanie|  2.99|2007-05-14 13:44:...|\n",
      "|         64|    Judith|  4.99|2007-05-14 13:44:...|\n",
      "|          5| Elizabeth|  0.99|2007-05-14 13:44:...|\n",
      "|         42|   Carolyn|  0.00|2007-05-14 13:44:...|\n",
      "|         60|   Mildred|  0.00|2007-05-14 13:44:...|\n",
      "|         42|   Carolyn|  5.98|2007-05-14 13:44:...|\n",
      "|         14|     Betty|  4.99|2007-05-14 13:44:...|\n",
      "|         43| Christine|  0.00|2007-05-14 13:44:...|\n",
      "|         15|     Helen|  3.98|2007-05-14 13:44:...|\n",
      "|         43| Christine|  3.98|2007-05-14 13:44:...|\n",
      "|         22|     Laura|  4.99|2007-05-14 13:44:...|\n",
      "|         44|     Marie|  4.99|2007-05-14 13:44:...|\n",
      "|         28|   Cynthia|  2.99|2007-05-14 13:44:...|\n",
      "|         29|    Angela|  0.99|2007-05-14 13:44:...|\n",
      "|         33|      Anna|  0.99|2007-05-14 13:44:...|\n",
      "|         60|   Mildred|  9.98|2007-05-14 13:44:...|\n",
      "|         52|     Julie|  4.99|2007-05-14 13:44:...|\n",
      "|         11|      Lisa|  0.99|2007-05-14 13:44:...|\n",
      "|         53|   Heather|  0.00|2007-05-14 13:44:...|\n",
      "|         21|  Michelle|  2.99|2007-05-14 13:44:...|\n",
      "+-----------+----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.join(F.broadcast(df2),on = ['customer_id'], how = 'inner')\\\n",
    "   .orderBy('payment_date',ascending = False)\\\n",
    "   .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673a817-94dc-4a20-b3d1-67577eb5d4a3",
   "metadata": {},
   "source": [
    "# INNER JOIN with an Alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d9796dc-9a73-4365-b155-4f27b7b14102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_join(df1,df2,on: list = [],how: str = 'inner'):\n",
    "    if not on:\n",
    "        on = list(set(df1.columns).intersection(set(df2.columns)))\n",
    "    return df1.join(df2,on = on, how = how)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5daa939-f024-4c06-addf-59d15912177c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"SELECT\n",
    "\tcustomer_id,\n",
    "\tfirst_name,\n",
    "    last_name\n",
    "FROM\n",
    "\tcustomer\n",
    "\"\"\"\n",
    "query2 = \"\"\"SELECT customer_id,staff_id,amount,payment_date FROM payment\"\"\"\n",
    "query3 = \"\"\"SELECT staff_id,first_name AS staff_first_name,last_name AS staff_last_name\n",
    "FROM staff\"\"\"\n",
    "df1 = spark.sql(query1)\n",
    "df2 = spark.sql(query2)\n",
    "df3 = spark.sql(query3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae97b2c-e14a-4417-a930-7c107bc5d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = reduce(spark_join,[df1,df2,df3]).orderBy('payment_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32d87a0f-d6c5-4466-8bca-2ca7a279e406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+----------+---------+------+--------------------+----------------+---------------+\n",
      "|staff_id|customer_id|first_name|last_name|amount|        payment_date|staff_first_name|staff_last_name|\n",
      "+--------+-----------+----------+---------+------+--------------------+----------------+---------------+\n",
      "|       2|        416|   Jeffery|   Pinson|  2.99|2007-02-14 21:21:...|             Jon|       Stephens|\n",
      "|       2|        516|     Elmer|      Noe|  4.99|2007-02-14 21:23:...|             Jon|       Stephens|\n",
      "|       1|        239|    Minnie|   Romero|  4.99|2007-02-14 21:29:...|            Mike|        Hillyer|\n",
      "|       2|        592|  Terrance|    Roush|  6.99|2007-02-14 21:41:...|             Jon|       Stephens|\n",
      "|       1|         49|     Joyce|  Edwards|  0.99|2007-02-14 21:44:...|            Mike|        Hillyer|\n",
      "|       2|        264| Gwendolyn|      May|  3.99|2007-02-14 21:44:...|             Jon|       Stephens|\n",
      "|       1|         46| Catherine| Campbell|  4.99|2007-02-14 21:45:...|            Mike|        Hillyer|\n",
      "|       2|        481|    Herman|   Devore|  2.99|2007-02-14 22:03:...|             Jon|       Stephens|\n",
      "|       2|        139|     Amber|    Dixon|  2.99|2007-02-14 22:11:...|             Jon|       Stephens|\n",
      "|       2|        595|  Terrence|Gunderson|  2.99|2007-02-14 22:16:...|             Jon|       Stephens|\n",
      "|       2|        191|  Jeanette|   Greene|  2.99|2007-02-14 22:23:...|             Jon|       Stephens|\n",
      "|       2|         95|     Paula|   Bryant|  2.99|2007-02-14 22:41:...|             Jon|       Stephens|\n",
      "|       2|        197|       Sue|   Peters|  2.99|2007-02-14 22:43:...|             Jon|       Stephens|\n",
      "|       1|        512|     Cecil|    Vines|  6.99|2007-02-14 22:57:...|            Mike|        Hillyer|\n",
      "|       2|        210|      Ella|   Oliver|  2.99|2007-02-14 23:01:...|             Jon|       Stephens|\n",
      "|       1|        119|    Sherry| Marshall|  7.99|2007-02-14 23:05:...|            Mike|        Hillyer|\n",
      "|       2|        432|     Edwin|     Burk|  5.99|2007-02-14 23:07:...|             Jon|       Stephens|\n",
      "|       1|        546|     Kelly|    Knott|  1.99|2007-02-14 23:10:...|            Mike|        Hillyer|\n",
      "|       1|        196|      Alma|   Austin|  5.99|2007-02-14 23:13:...|            Mike|        Hillyer|\n",
      "|       1|          1|      Mary|    Smith|  5.99|2007-02-14 23:22:...|            Mike|        Hillyer|\n",
      "+--------+-----------+----------+---------+------+--------------------+----------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be96b4dd-5a6e-411f-b02b-8ea12e35dc52",
   "metadata": {},
   "source": [
    "# LEFT JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37eae3ab-7802-4791-90fc-9280ec0321b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"\"\"SELECT film_id,\n",
    "                   title\n",
    "            FROM film\n",
    "\"\"\"\n",
    "query2 = \"\"\"SELECT film_id,inventory_id FROM inventory\"\"\"\n",
    "df1 = spark.sql(query1)\n",
    "df2 = spark.sql(query2)\n",
    "df_join = spark_join(df1,df2,how = 'left',on = ['film_id']).orderBy('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19bb5fc4-9af8-480f-892b-95810294156c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+------------+\n",
      "|film_id|           title|inventory_id|\n",
      "+-------+----------------+------------+\n",
      "|      1|Academy Dinosaur|           1|\n",
      "|      1|Academy Dinosaur|           8|\n",
      "|      1|Academy Dinosaur|           7|\n",
      "|      1|Academy Dinosaur|           6|\n",
      "|      1|Academy Dinosaur|           5|\n",
      "|      1|Academy Dinosaur|           4|\n",
      "|      1|Academy Dinosaur|           3|\n",
      "|      1|Academy Dinosaur|           2|\n",
      "|      2|  Ace Goldfinger|          11|\n",
      "|      2|  Ace Goldfinger|          10|\n",
      "|      2|  Ace Goldfinger|           9|\n",
      "|      3|Adaptation Holes|          13|\n",
      "|      3|Adaptation Holes|          12|\n",
      "|      3|Adaptation Holes|          15|\n",
      "|      3|Adaptation Holes|          14|\n",
      "|      4|Affair Prejudice|          22|\n",
      "|      4|Affair Prejudice|          21|\n",
      "|      4|Affair Prejudice|          20|\n",
      "|      4|Affair Prejudice|          19|\n",
      "|      4|Affair Prejudice|          18|\n",
      "+-------+----------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38078bd8-3d2c-434e-a801-a668b140b4ad",
   "metadata": {},
   "source": [
    "# RIGHT JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77a89765-15c1-4297-92a0-673a7aa92709",
   "metadata": {},
   "outputs": [],
   "source": [
    "film_schema = StructType([ \\\n",
    "    StructField(\"film_id\",IntegerType(),True), \\\n",
    "    StructField(\"title\",StringType(),True)\n",
    "  ])\n",
    "films = [(1,'Joker'),\n",
    "            (2,'Avengers'),\n",
    "            (3,'Parasite')]\n",
    "columns = ['film_id','title']\n",
    "rdd = spark.sparkContext.parallelize(films)\n",
    "df1 = spark.createDataFrame(rdd, schema = film_schema)\n",
    "ratings_schema = StructType([ \\\n",
    "    StructField(\"review_id\",IntegerType(),True),\n",
    "    StructField(\"film_id\",IntegerType(),True),\n",
    "    StructField(\"review\",StringType(),True),\n",
    "  ])\n",
    "ratings = [(1,1,'Excellent'),\n",
    "         (2,1,'Awesome'),\n",
    "         (3,2,'Cool'),\n",
    "         (4,None,'Beautiful')]\n",
    "columns = ['review_id','film_id','review']\n",
    "rdd = spark.sparkContext.parallelize(ratings)\n",
    "df2 = spark.createDataFrame(rdd, schema = ratings_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecc0724d-7737-4f57-91e2-f44966df5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = spark_join(df1,df2,how = 'right',on = ['film_id']).select(['review','title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbcdda43-7bc5-46ae-8aa7-7c8044f658b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 26:====>           (4 + 12) / 16][Stage 27:>                (0 + 5) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|   review|   title|\n",
      "+---------+--------+\n",
      "|Excellent|   Joker|\n",
      "|  Awesome|   Joker|\n",
      "|     Cool|Avengers|\n",
      "|Beautiful|    null|\n",
      "+---------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d7a310-d22e-4368-af4c-24da22077ca1",
   "metadata": {},
   "source": [
    "## Filtering example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "675c0563-25c2-40b8-9e20-c5bbedd8ca3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|   review|title|\n",
      "+---------+-----+\n",
      "|Beautiful| null|\n",
      "+---------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.filter(df_join['title'].isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7e91ed-a6e8-4737-a76b-2f4890bda9df",
   "metadata": {},
   "source": [
    "# Turning a RIGHT JOIN into a LEFT JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9fe02d0-47d5-405b-8d93-8c8584e533b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = spark_join(df2,df1,how = 'left',on = ['film_id']).select(['review','title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10e6c0f0-a39b-47fc-bf25-b133e6d1ff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n",
      "|   review|   title|\n",
      "+---------+--------+\n",
      "|Excellent|   Joker|\n",
      "|  Awesome|   Joker|\n",
      "|     Cool|Avengers|\n",
      "|Beautiful|    null|\n",
      "+---------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc49522-750b-4dfd-9f38-e1bf6d5bfbda",
   "metadata": {},
   "source": [
    "# SELF JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0b69761-b43f-47a2-bf82-d36ed8f7e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_schema = StructType([ \\\n",
    "    StructField(\"employee_id\",IntegerType(),True),\n",
    "    StructField(\"first_name\",StringType(),True),\n",
    "    StructField(\"last_name\",StringType(),True),\n",
    "    StructField(\"manager_id\",IntegerType(),True),\n",
    "  ])\n",
    "employees = [(1, 'Windy', 'Hays', None),\n",
    "             (2, 'Ava', 'Christensen', 1),\n",
    "             (3, 'Hassan', 'Conner', 1),\n",
    "             (4, 'Anna', 'Reeves', 2),\n",
    "             (5, 'Sau', 'Norman', 2),\n",
    "             (6, 'Kelsie', 'Hays', 3),\n",
    "             (7, 'Tory', 'Goff', 3),\n",
    "             (8, 'Salley', 'Lester', 3)]\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(employees)\n",
    "df1 = spark.createDataFrame(rdd, schema = company_schema)\n",
    "df1 = df1.select('employee_id','manager_id',F.concat_ws(' ', df1['first_name'], df1['last_name']).alias('employee_full_name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d83008d-3f73-4fe2-8140-81346bbe1448",
   "metadata": {},
   "source": [
    "## query example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cc89845-b485-4e9b-9b68-89d629ba4839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df1.alias('t1')\\\n",
    "             .join(df1.alias('t2'),\n",
    "                   F.col('t1.employee_id') == F.col('t2.manager_id'),\n",
    "                   'inner')\\\n",
    "            .select(*[\n",
    "                F.col('t1.employee_full_name').alias('manager'),\n",
    "                F.col('t2.employee_full_name').alias('employee')\n",
    "            ]).orderBy('manager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f02c7bcd-9f0d-4083-8b5a-d6db72b2047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|        manager|       employee|\n",
      "+---------------+---------------+\n",
      "|Ava Christensen|    Anna Reeves|\n",
      "|Ava Christensen|     Sau Norman|\n",
      "|  Hassan Conner|    Kelsie Hays|\n",
      "|  Hassan Conner|      Tory Goff|\n",
      "|  Hassan Conner|  Salley Lester|\n",
      "|     Windy Hays|Ava Christensen|\n",
      "|     Windy Hays|  Hassan Conner|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed1d926-2c24-4159-ba41-bb31df64cc8b",
   "metadata": {},
   "source": [
    "## Showing who's the boss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "585eb82f-0d96-4754-9381-d23f3e028594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df1.alias('e')\\\n",
    "             .join(df1.alias('m'),\n",
    "                   F.col('m.employee_id') == F.col('e.manager_id'),\n",
    "                   'left')\\\n",
    "            .select(*[\n",
    "                F.col('e.employee_full_name').alias('employee'),\n",
    "                F.col('m.employee_full_name').alias('manager')\n",
    "                \n",
    "            ]).orderBy('manager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d03367d-72bf-4929-a20e-2185c3cf0cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|       employee|        manager|\n",
      "+---------------+---------------+\n",
      "|     Windy Hays|           null|\n",
      "|    Anna Reeves|Ava Christensen|\n",
      "|     Sau Norman|Ava Christensen|\n",
      "|    Kelsie Hays|  Hassan Conner|\n",
      "|      Tory Goff|  Hassan Conner|\n",
      "|  Salley Lester|  Hassan Conner|\n",
      "|Ava Christensen|     Windy Hays|\n",
      "|  Hassan Conner|     Windy Hays|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bacffef-5922-47d9-b4b9-05c03b6d7cd7",
   "metadata": {},
   "source": [
    "# FULL OUTER JOIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b8e0340-d4e1-4ccd-a260-ba627892a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "departments_schema = StructType([ \\\n",
    "    StructField(\"department_id\",IntegerType(),True),\n",
    "    StructField(\"department_name\",StringType(),True)])\n",
    "employee_schema = StructType([ \\\n",
    "    StructField(\"employee_id\",IntegerType(),True),\n",
    "    StructField(\"employee_name\",StringType(),True),\n",
    "    StructField(\"department_id\",IntegerType(),True)])\n",
    "departments = [(1, 'Sales'),\n",
    "               (2, 'Marketing'),\n",
    "               (3, 'HR'),\n",
    "               (4, 'IT'),\n",
    "               (5,'Production')]\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(departments)\n",
    "df1 = spark.createDataFrame(rdd, schema = departments_schema)\n",
    "employees = [(1,'Bette Nicholson', 1),\n",
    "        \t (2,'Christian Gable', 1),\n",
    "        \t (3,'Joe Swank', 2),\n",
    "        \t (4,'Fred Costner', 3),\n",
    "        \t (5,'Sandra Kilmer', 4),\n",
    "        \t (6,'Julia Mcqueen', None)]\n",
    "rdd = spark.sparkContext.parallelize(employees)\n",
    "df2 = spark.createDataFrame(rdd, schema = employee_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3258710-efbb-4f7a-84cf-d34e38e83e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|  employee_name|department_name|\n",
      "+---------------+---------------+\n",
      "|  Julia Mcqueen|           null|\n",
      "|Christian Gable|          Sales|\n",
      "|Bette Nicholson|          Sales|\n",
      "|      Joe Swank|      Marketing|\n",
      "|   Fred Costner|             HR|\n",
      "|  Sandra Kilmer|             IT|\n",
      "|           null|     Production|\n",
      "+---------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_join(df1,df2,how = 'full_outer').select('employee_name','department_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6c75475-ba7d-4db1-8bf8-3c7b39643513",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df2.select(F.col('employee_name').alias('employee_A')).crossJoin(df2.select(F.col('employee_name').alias('employee_B')))\n",
    "df_join = df_join.filter(F.col('employee_A') != F.col('employee_B'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13d3f591-0bd6-47c9-9d93-b67dd5eda192",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 64:=====================================================>(114 + 2) / 116]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---------------+\n",
      "|     employee_A|     employee_B|\n",
      "+---------------+---------------+\n",
      "|Bette Nicholson|Christian Gable|\n",
      "|Bette Nicholson|      Joe Swank|\n",
      "|Bette Nicholson|   Fred Costner|\n",
      "|Bette Nicholson|  Sandra Kilmer|\n",
      "|Bette Nicholson|  Julia Mcqueen|\n",
      "|Christian Gable|Bette Nicholson|\n",
      "|Christian Gable|      Joe Swank|\n",
      "|Christian Gable|   Fred Costner|\n",
      "|Christian Gable|  Sandra Kilmer|\n",
      "|Christian Gable|  Julia Mcqueen|\n",
      "|      Joe Swank|Bette Nicholson|\n",
      "|      Joe Swank|Christian Gable|\n",
      "|      Joe Swank|   Fred Costner|\n",
      "|      Joe Swank|  Sandra Kilmer|\n",
      "|      Joe Swank|  Julia Mcqueen|\n",
      "|   Fred Costner|Bette Nicholson|\n",
      "|   Fred Costner|Christian Gable|\n",
      "|   Fred Costner|      Joe Swank|\n",
      "|   Fred Costner|  Sandra Kilmer|\n",
      "|   Fred Costner|  Julia Mcqueen|\n",
      "+---------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2bcc10d9-7444-4074-a173-91ce5d050079",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df1.select(F.col('department_name').alias('department_A')).crossJoin(df1.select(F.col('department_name').alias('department_B')))\n",
    "df_join = df_join.filter(F.col('department_A') != F.col('department_B'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "093bd4ad-6194-4c4a-8500-416de70a3423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 69:==================================================>   (122 + 9) / 131]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|department_A|department_B|\n",
      "+------------+------------+\n",
      "|       Sales|   Marketing|\n",
      "|       Sales|          HR|\n",
      "|       Sales|          IT|\n",
      "|       Sales|  Production|\n",
      "|   Marketing|       Sales|\n",
      "|   Marketing|          HR|\n",
      "|   Marketing|          IT|\n",
      "|   Marketing|  Production|\n",
      "|          HR|       Sales|\n",
      "|          HR|   Marketing|\n",
      "|          HR|          IT|\n",
      "|          HR|  Production|\n",
      "|          IT|       Sales|\n",
      "|          IT|   Marketing|\n",
      "|          IT|          HR|\n",
      "|          IT|  Production|\n",
      "|  Production|       Sales|\n",
      "|  Production|   Marketing|\n",
      "|  Production|          HR|\n",
      "|  Production|          IT|\n",
      "+------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a368a-6c1b-4383-b3aa-73dea67573b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
