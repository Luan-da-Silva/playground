{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a54bd986-95db-4a81-9abf-6bc2eaa4a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_tools.setup import setup\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a43aa6dd-198f-4c6f-8072-cf4c60d58b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.dataframe import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13159271-405b-45e5-8e21-4270fa7aa40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/22 19:38:11 WARN Utils: Your hostname, luan-Dell-G15-5520 resolves to a loopback address: 127.0.1.1; using 192.168.1.12 instead (on interface wlp0s20f3)\n",
      "23/10/22 19:38:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/10/22 19:38:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/22 19:38:12 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as \"spark\"\n"
     ]
    }
   ],
   "source": [
    "spark = setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b228980-73ee-4ded-9c76-34387232bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_query(query,SparkSession = spark,n = 20):\n",
    "    return SparkSession.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a38371-ed42-4bc8-a03a-bce1e99540dd",
   "metadata": {},
   "source": [
    "# Exercises Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e264b-c4ca-4f66-990e-39aa3bca0e2d",
   "metadata": {},
   "source": [
    "## 1 - pure SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214f9f4c-ce77-4e01-84f2-3627fbea06df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Billy|   Poulin|\n",
      "|      Dana|     Hart|\n",
      "|      Ella|   Oliver|\n",
      "|     Jason|Morrissey|\n",
      "|  Kimberly|      Lee|\n",
      "|   Rebecca|    Scott|\n",
      "|     Tommy|  Collazo|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query =  \"\"\"SELECT\n",
    "                \tfirst_name,\n",
    "                    last_name\n",
    "              FROM\n",
    "                \tcustomer\n",
    "              WHERE\n",
    "                \tfirst_name IN ('Jason',\n",
    "                                   'Zack',\n",
    "                                   'Trini',\n",
    "                                   'Kimberly',\n",
    "                                   'Billy',\n",
    "                                   'Tommy')\n",
    "                    OR last_name IN ('Lee','Scott','Kwan','Hart','Cranston','Oliver')\n",
    "              ORDER BY \n",
    "                    first_name;\n",
    "              \"\"\"\n",
    "show_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a7a52-697e-4206-86ca-b509dbfc3250",
   "metadata": {},
   "source": [
    "## 2 - redoing all with PysparkSQL API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24503dfc-0812-42e2-8e61-e5a6408f28d0",
   "metadata": {},
   "source": [
    "### Example 1: Filtering names from the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a589af1c-a352-4958-9881-81da5cb5387e",
   "metadata": {},
   "source": [
    "### Getting the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "949c4e30-eb8f-4295-ae48-a6f1eef0399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * FROM customer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668fc03b-a920-4c76-a2bf-6a05b33e110f",
   "metadata": {},
   "source": [
    "### First form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1483c056-028c-48cc-9c5e-3133ddfa807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Jamie|     Rice|\n",
      "|     Jamie|    Waugh|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*['first_name','last_name']).filter(\"first_name = 'Jamie'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efdd1da-1f02-41d5-9f05-febb97ab058c",
   "metadata": {},
   "source": [
    "### Alternative version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef960b3-ca59-4d60-b40f-b89883795202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Jamie|     Rice|\n",
      "|     Jamie|    Waugh|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*['first_name','last_name']).filter(df[\"first_name\"] == 'Jamie').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f76cad3-5b71-49b4-82e7-f9493092ce03",
   "metadata": {},
   "source": [
    "### Where is a filter alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e63646bb-bebf-4e04-afd8-26bc8cc3a861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Jamie|     Rice|\n",
      "|     Jamie|    Waugh|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*['first_name','last_name']).where(df[\"first_name\"] == 'Jamie').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e81a9-c080-46ae-9009-29164b9dbe96",
   "metadata": {},
   "source": [
    "## Example 2 with variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76d9959d-a4b8-43e6-bd4f-5758e6a60c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Jamie|     Rice|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*['first_name','last_name']).filter(\"first_name = 'Jamie' AND last_name = 'Rice' \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88783a5c-effd-4641-b5d9-d30d21f0f1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Laura|Rodriguez|\n",
      "|      Adam|    Gooch|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*['first_name','last_name']).filter(\"last_name = 'Rodriguez' OR first_name = 'Adam'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec526c07-8128-4912-b48c-e6356afc093b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Jamie|     Rice|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*['first_name','last_name']).filter((df[\"first_name\"] == 'Jamie') & (df[\"last_name\"] == 'Rice')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdb94681-18cf-4b3c-ba22-c9418dfac8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Laura|Rodriguez|\n",
      "|      Adam|    Gooch|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*['first_name','last_name']).filter((df[\"first_name\"] == 'Adam') | (df[\"last_name\"] == 'Rodriguez')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f90c0b4-e642-4c5f-8063-1b77e7b595ed",
   "metadata": {},
   "source": [
    "## Example 3 with variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "add45665-355d-4ac7-91e6-fb755ed117b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|       Ann|    Evans|\n",
      "|      Anne|   Powell|\n",
      "|     Annie|  Russell|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*['first_name','last_name']).filter(\"first_name  IN ('Ann','Anne','Annie')\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9663aca0-dfe4-4a18-bf94-af0d9e519b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|       Ann|    Evans|\n",
      "|      Anne|   Powell|\n",
      "|     Annie|  Russell|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*['first_name','last_name']).filter(df[\"first_name\"].isin(['Ann','Anne','Annie'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b81424c-4781-47ca-95cd-b482ab8b3b0f",
   "metadata": {},
   "source": [
    "### Like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bede6ccf-2061-4d3f-b2a1-29ad91730e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|      Anna|     Hill|\n",
      "|       Ann|    Evans|\n",
      "|      Anne|   Powell|\n",
      "|     Annie|  Russell|\n",
      "|   Annette|    Olson|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*['first_name','last_name']).filter(df[\"first_name\"].like(\"Ann%\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63ef1a63-a3ea-46e7-a905-b01d03ea1bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|      Anna|     Hill|\n",
      "|       Ann|    Evans|\n",
      "|      Anne|   Powell|\n",
      "|     Annie|  Russell|\n",
      "|   Annette|    Olson|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(*['first_name','last_name']).filter(\"first_name LIKE 'Ann%'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363184aa-b413-4c71-82b4-4104fcf11247",
   "metadata": {},
   "source": [
    "## Example 4: combining wildcards, string functions and BETWEEN clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f819841-ee37-4753-8c37-8c52e6f50673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|first_name|name_length|\n",
      "+----------+-----------+\n",
      "|       Amy|          3|\n",
      "|       Ann|          3|\n",
      "|       Ana|          3|\n",
      "|      Anna|          4|\n",
      "|      Anne|          4|\n",
      "|      Alma|          4|\n",
      "|      Adam|          4|\n",
      "|      Alan|          4|\n",
      "|      Alex|          4|\n",
      "|      Andy|          4|\n",
      "|     Alice|          5|\n",
      "|     Annie|          5|\n",
      "|     Anita|          5|\n",
      "|     Amber|          5|\n",
      "|     April|          5|\n",
      "|     Agnes|          5|\n",
      "|     Aaron|          5|\n",
      "|     Allen|          5|\n",
      "|     Alvin|          5|\n",
      "|     Angel|          5|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('first_name',F.length('first_name')\\\n",
    "   .alias('name_length'))\\\n",
    "   .filter((F.col(\"first_name\")\\\n",
    "   .like(\"A%\")) & (F.col('name_length')\\\n",
    "   .between(3,5))).orderBy(F.col('name_length')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c166d4f-09af-4fb0-9749-26abcfdd2bb6",
   "metadata": {},
   "source": [
    "## Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae818a35-850f-4c59-8333-31fe5d90b36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|    Brandy|   Graves|\n",
      "|   Brandon|     Huey|\n",
      "|      Brad|  Mccurdy|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('first_name','last_name')\\\n",
    "   .filter((F.col(\"first_name\")\\\n",
    "   .like(\"Bra%\")) & (~F.col('last_name')\\\n",
    "   .like(\"Motley\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e0bf26-01f8-490f-a40c-5cf08a7f1fc8",
   "metadata": {},
   "source": [
    "## Example 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "666ca793-f7c9-4ea3-9053-b8a46780731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film = spark.sql(\"SELECT * FROM film\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6637f04-457c-4c92-bd14-ddb6789e8a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+------------+\n",
      "|film_id|           title|release_year|\n",
      "+-------+----------------+------------+\n",
      "|      1|Academy Dinosaur|        2006|\n",
      "|      2|  Ace Goldfinger|        2006|\n",
      "|      3|Adaptation Holes|        2006|\n",
      "|      4|Affair Prejudice|        2006|\n",
      "|      5|     African Egg|        2006|\n",
      "+-------+----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_film.select('film_id','title','release_year').orderBy('film_id').limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020250ec-d328-43a6-bc84-ee5d7bd5c30f",
   "metadata": {},
   "source": [
    "## Example 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3e3af1a-b5b7-4d90-b299-a5d8f4fd48e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+------------+\n",
      "|film_id|           title|release_year|\n",
      "+-------+----------------+------------+\n",
      "|      1|Academy Dinosaur|        2006|\n",
      "|      2|  Ace Goldfinger|        2006|\n",
      "|      3|Adaptation Holes|        2006|\n",
      "|      4|Affair Prejudice|        2006|\n",
      "|      5|     African Egg|        2006|\n",
      "+-------+----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_film.select('film_id','title','release_year').orderBy('film_id').limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d3d5c2-fa88-46d2-8537-10dcc72db2a8",
   "metadata": {},
   "source": [
    "### Offset is NOT present in pyspark 3.4.1. You can change container parameters to install spark 3.5.0 and pyspark 3.5.0. Here, we will implement offset logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01e258c9-37a0-458d-a7ca-c5e3cc43af0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'offset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf_film\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilm_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtitle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelease_year\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morderBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilm_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moffset\u001b[49m(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py:2977\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2944\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   2945\u001b[0m \n\u001b[1;32m   2946\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2974\u001b[0m \u001b[38;5;124;03m+---+\u001b[39;00m\n\u001b[1;32m   2975\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 2977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   2978\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   2979\u001b[0m     )\n\u001b[1;32m   2980\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'offset'"
     ]
    }
   ],
   "source": [
    "df_film.select('film_id','title','release_year').orderBy('film_id').limit(5).offset(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6424a128-db6f-411a-a0bc-bd7299ca2fea",
   "metadata": {},
   "source": [
    "### Implementing OFFSET idea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71cab4d8-825b-48bd-9358-e5b846e75add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+------------+\n",
      "|film_id|          title|release_year|\n",
      "+-------+---------------+------------+\n",
      "|     11|Alamo Videotape|        2006|\n",
      "|     12| Alaska Phantom|        2006|\n",
      "|     13|    Ali Forever|        2006|\n",
      "|     14| Alice Fantasia|        2006|\n",
      "|     15|   Alien Center|        2006|\n",
      "+-------+---------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "offset = 10\n",
    "df_film.select('film_id','title','release_year').orderBy('film_id').filter(f'film_id>{offset}').limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d85d43-67f7-4793-bf3f-5f866db85032",
   "metadata": {},
   "source": [
    "## Example 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64a66ef7-8b0c-4a8a-ba1e-59253c1a2457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------+\n",
      "|film_id|              title|rental_rate|\n",
      "+-------+-------------------+-----------+\n",
      "|      7|    Airplane Sierra|       4.99|\n",
      "|    384|   Grosse Wonderful|       4.99|\n",
      "|      8|    Airport Pollock|       4.99|\n",
      "|     98|  Bright Encounters|       4.99|\n",
      "|      2|     Ace Goldfinger|       4.99|\n",
      "|    133|    Chamber Italian|       4.99|\n",
      "|     10|   Aladdin Calendar|       4.99|\n",
      "|     13|        Ali Forever|       4.99|\n",
      "|     20|Amelie Hellfighters|       4.99|\n",
      "|     21|    American Circus|       4.99|\n",
      "+-------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_film.select('film_id','title','rental_rate').orderBy('rental_rate',ascending = False).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c74dac-f1dd-48d2-836b-f37443a9f287",
   "metadata": {},
   "source": [
    "## More examples: most are trivial with the above answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9346074-dbe5-4117-9282-262897661e02",
   "metadata": {},
   "source": [
    "### Non trivial one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0397eaac-4dbe-46b8-859e-eb1b20097399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+----------+\n",
      "|customer_id|first_name| last_name|\n",
      "+-----------+----------+----------+\n",
      "|         37|    Pamela|     Baker|\n",
      "|         47|   Frances|    Parker|\n",
      "|         48|       Ann|     Evans|\n",
      "|         65|      Rose|    Howard|\n",
      "|         73|   Beverly|    Brooks|\n",
      "|         75|     Tammy|   Sanders|\n",
      "|         93|   Phyllis|    Foster|\n",
      "|        114|     Grace|     Ellis|\n",
      "|        119|    Sherry|  Marshall|\n",
      "|        131|    Monica|     Hicks|\n",
      "|        158|  Veronica|     Stone|\n",
      "|        167|     Sally|    Pierce|\n",
      "|        182|     Renee|      Lane|\n",
      "|        184|    Vivian|      Ruiz|\n",
      "|        185|   Roberta|    Harper|\n",
      "|        211|    Stacey|Montgomery|\n",
      "|        239|    Minnie|    Romero|\n",
      "|        247|    Stella|    Moreno|\n",
      "|        251|    Vickie|    Brewer|\n",
      "|        256|     Mabel|   Holland|\n",
      "+-----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customer = spark.sql('SELECT * FROM customer')\n",
    "df_customer.select('customer_id',\n",
    "                \t'first_name',\n",
    "                \t'last_name')\\\n",
    "                    .filter(\"\"\"customer_id IN (\n",
    "                \t\tSELECT customer_id\n",
    "                \t\tFROM rental\n",
    "                \t\tWHERE CAST (return_date AS DATE) = '2005-05-27')\"\"\").orderBy('customer_id').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fe6813-128e-4b5b-9a43-301f3bde6a03",
   "metadata": {},
   "source": [
    "## Not and IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a56b0554-f7af-42ce-8bfa-b57c8538e7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+-------------------+\n",
      "|customer_id|rental_id|        return_date|\n",
      "+-----------+---------+-------------------+\n",
      "|        459|        2|2005-05-28 19:40:33|\n",
      "|        408|        3|2005-06-01 22:12:39|\n",
      "|        333|        4|2005-06-03 01:43:41|\n",
      "|        222|        5|2005-06-02 04:33:21|\n",
      "|        549|        6|2005-05-27 01:32:07|\n",
      "|        269|        7|2005-05-29 20:34:53|\n",
      "|        239|        8|2005-05-27 23:33:46|\n",
      "|        126|        9|2005-05-28 00:22:40|\n",
      "|        399|       10|2005-05-31 22:44:21|\n",
      "|        142|       11|2005-06-02 20:56:02|\n",
      "|        261|       12|2005-05-30 05:44:27|\n",
      "|        334|       13|2005-05-30 04:28:55|\n",
      "|        446|       14|2005-05-26 02:56:15|\n",
      "|        319|       15|2005-06-03 03:30:22|\n",
      "|        316|       16|2005-05-26 04:42:11|\n",
      "|        575|       17|2005-05-27 00:43:36|\n",
      "|         19|       18|2005-05-31 06:35:47|\n",
      "|        456|       19|2005-05-31 06:00:24|\n",
      "|        185|       20|2005-05-27 02:20:41|\n",
      "|        388|       21|2005-05-26 01:01:46|\n",
      "+-----------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rental = spark.sql('SELECT * FROM rental')\n",
    "df_rental.select('customer_id',\n",
    "                 'rental_id',\n",
    "                 'return_date').where(~F.col('customer_id').isin([1,2])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e2a7c2-68ff-457c-8a5e-9c9980b8b49b",
   "metadata": {},
   "source": [
    "## Not and BETWEEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "13887ad5-41d8-4fe7-b12b-a4328837d454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------+\n",
      "|customer_id|payment_id|amount|\n",
      "+-----------+----------+------+\n",
      "|        341|     17503|  7.99|\n",
      "|        341|     17504|  1.99|\n",
      "|        341|     17505|  7.99|\n",
      "|        341|     17506|  2.99|\n",
      "|        341|     17507|  7.99|\n",
      "|        341|     17508|  5.99|\n",
      "|        342|     17509|  5.99|\n",
      "|        342|     17510|  5.99|\n",
      "|        342|     17511|  2.99|\n",
      "|        343|     17512|  4.99|\n",
      "|        343|     17513|  6.99|\n",
      "|        343|     17514|  0.99|\n",
      "|        343|     17515|  0.99|\n",
      "|        343|     17516|  6.99|\n",
      "|        343|     17518|  0.99|\n",
      "|        344|     17519|  3.99|\n",
      "|        344|     17520|  4.99|\n",
      "|        344|     17521|  0.99|\n",
      "|        345|     17522|  0.99|\n",
      "|        345|     17523|  4.99|\n",
      "+-----------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_payment = spark.sql('SELECT * FROM payment')\n",
    "df_payment.select('customer_id',\n",
    "                  'payment_id',\n",
    "                  'amount').where(~df_payment.amount.between(8,9)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21dbe20-9fa2-4e05-a31a-fffcaa76e353",
   "metadata": {},
   "source": [
    "## BETWEEN and Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b777699f-8a3f-4963-821c-8e4649ecb9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------+--------------------+\n",
      "|customer_id|payment_id|amount|        payment_date|\n",
      "+-----------+----------+------+--------------------+\n",
      "|        368|     17610|  0.99|2007-02-14 23:25:...|\n",
      "|        370|     17617|  6.99|2007-02-14 23:33:...|\n",
      "|        402|     17743|  4.99|2007-02-14 23:53:...|\n",
      "|        416|     17793|  2.99|2007-02-14 21:21:...|\n",
      "|        432|     17854|  5.99|2007-02-14 23:07:...|\n",
      "|        481|     18051|  2.99|2007-02-14 22:03:...|\n",
      "|        512|     18155|  6.99|2007-02-14 22:57:...|\n",
      "|        516|     18173|  4.99|2007-02-14 21:23:...|\n",
      "|        546|     18276|  1.99|2007-02-14 23:10:...|\n",
      "|        561|     18322|  2.99|2007-02-14 23:52:...|\n",
      "|        592|     18441|  6.99|2007-02-14 21:41:...|\n",
      "|        595|     18456|  2.99|2007-02-14 22:16:...|\n",
      "|          1|     18495|  5.99|2007-02-14 23:22:...|\n",
      "|         46|     18686|  4.99|2007-02-14 21:45:...|\n",
      "|         49|     18698|  0.99|2007-02-14 21:44:...|\n",
      "|         95|     18870|  2.99|2007-02-14 22:41:...|\n",
      "|        119|     18963|  7.99|2007-02-14 23:05:...|\n",
      "|        139|     19036|  2.99|2007-02-14 22:11:...|\n",
      "|        173|     19159|  2.99|2007-02-14 23:32:...|\n",
      "|        186|     19212|  4.99|2007-02-14 23:47:...|\n",
      "+-----------+----------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM payment').select(*['customer_id','payment_id','amount','payment_date']).filter(F.col('payment_date').between('2007-02-07','2007-02-15')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587f519a-6b8e-4ec4-925a-372cc14490c3",
   "metadata": {},
   "source": [
    "## IS NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f3e04e5c-f6df-442a-af71-24f992b2e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([ \\\n",
    "    StructField(\"id\",IntegerType(),True), \\\n",
    "    StructField(\"first_name\",StringType(),True), \\\n",
    "    StructField(\"last_name\",StringType(),True), \\\n",
    "    StructField(\"email\", StringType(), True), \\\n",
    "    StructField(\"phone\", StringType(), True), \\\n",
    "  ])\n",
    "contacts = [(1,\"John\",\"Doe\",'john.doe@example.com',None),\n",
    "            (2,\"Lily\",\"Bush\",'lily.bush@example.com','(408-234-2764)')]\n",
    "columns = ['id','first_name','last_name','email','phone']\n",
    "rdd = spark.sparkContext.parallelize(contacts)\n",
    "df_spark = spark.createDataFrame(rdd, schema = schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f170c28-47ba-47b6-a48f-9646fbff1390",
   "metadata": {},
   "source": [
    "### NULL IS NOT equal to NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c313ffb2-9943-43c8-b1a4-ce295e22596b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+-----+-----+\n",
      "| id|first_name|last_name|email|phone|\n",
      "+---+----------+---------+-----+-----+\n",
      "+---+----------+---------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('*').filter(F.col('phone') == None).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42d4c22c-84f1-449b-817f-4b728a30a480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+-----+\n",
      "| id|first_name|last_name|               email|phone|\n",
      "+---+----------+---------+--------------------+-----+\n",
      "|  1|      John|      Doe|john.doe@example.com| null|\n",
      "+---+----------+---------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('*').filter(F.col('phone').isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "673412e9-7c24-406a-ab49-ee664c5cda61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+---------+--------------------+--------------+\n",
      "| id|first_name|last_name|               email|         phone|\n",
      "+---+----------+---------+--------------------+--------------+\n",
      "|  2|      Lily|     Bush|lily.bush@example...|(408-234-2764)|\n",
      "+---+----------+---------+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.select('*').filter(~F.col('phone').isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ff0ff-bfc9-4ab8-ac87-945a95efb3e9",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ab52b884-01fe-41e7-812e-832a5cfd9505",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer = spark.sql(\"SELECT * FROM customer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5c9395ad-0976-4f4a-9881-992bde7c38b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|     Billy|   Poulin|\n",
      "|      Dana|     Hart|\n",
      "|      Ella|   Oliver|\n",
      "|     Jason|Morrissey|\n",
      "|  Kimberly|      Lee|\n",
      "|   Rebecca|    Scott|\n",
      "|     Tommy|  Collazo|\n",
      "+----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_customer.select('first_name','last_name')\\\n",
    "  .filter((F.col('first_name')\\\n",
    "  .isin(['Jason',\n",
    "         'Zack',\n",
    "         'Trini',\n",
    "         'Kimberly',\n",
    "         'Billy',\n",
    "         'Tommy'])) |\n",
    "         (F.col('last_name')\\\n",
    "  .isin(['Lee','Scott','Kwan','Hart','Cranston','Oliver']))).orderBy('first_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdf9a5c-d84c-43c6-98d2-2d12cb1ed90e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
